<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://evan-wang-13.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://evan-wang-13.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-12-23T22:57:00+00:00</updated><id>https://evan-wang-13.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Building MiniTorch</title><link href="https://evan-wang-13.github.io/blog/2024/MLE/" rel="alternate" type="text/html" title="Building MiniTorch"/><published>2024-12-21T00:00:00+00:00</published><updated>2024-12-21T00:00:00+00:00</updated><id>https://evan-wang-13.github.io/blog/2024/MLE</id><content type="html" xml:base="https://evan-wang-13.github.io/blog/2024/MLE/"><![CDATA[<p>In Machine Learning Engineering (MLE), taught by Prof. Sasha Rush, I built <a href="https://minitorch.github.io/">MiniTorch</a>, a ground-up implementation of PyTorch. Starting from basis scalar operations, I implemented a fully operational Python library for training and using neural networks.</p> <p>Getting to focus on the <em>engineering</em> side of Machine Learning Engineering was super cool. Now, when I call <code class="language-plaintext highlighter-rouge">torch.nn.Linear</code> or <code class="language-plaintext highlighter-rouge">loss.backward()</code>, I know what’s happening under the hood. These are my key takeaways! Note that I won’t be discussing the fundamental theory behind ML (e.g. why we want to find the gradient of the loss function), as this blog focuses on the <em>why</em> and <em>how</em> of engineering ML code.</p> <h2 id="part-1-fundamentals">Part 1: Fundamentals</h2> <p>Our goal is to implement code that allows us to train large neural networks. This requires keeping track of many parameters, as well as tracing operations to compute gradients.</p> <p>We do this by using a <code class="language-plaintext highlighter-rouge">Module</code> building block that is maintained in a tree structure. Each module stores its own parameters, as well as its submodules.</p> <p>Why a tree structure?</p> <ul> <li>Trees naturally represent hierarchical structures, which are common neural networks (layers building on top of each other)</li> <li>Trees allow us to easily represent parallel operations</li> <li>Components and their owned parameters are clearly defined, which is useful for debugging, memory management, gradient tracking etc.</li> </ul> <p>For our base <code class="language-plaintext highlighter-rouge">Module</code> class, we define attributes</p> <ul> <li><code class="language-plaintext highlighter-rouge">_modules</code>: Storage of the child modules</li> <li><code class="language-plaintext highlighter-rouge">_parameters</code>: Storage of the module’s parameters</li> <li><code class="language-plaintext highlighter-rouge">training</code>: Whether the module is in training mode or evaluation mode</li> </ul> <p>This class will also have functions to collect named parameters, submodules, etc. Another note: we use magic methods to override the default behavior of Python, such as custom <code class="language-plaintext highlighter-rouge">getattr</code> and <code class="language-plaintext highlighter-rouge">setattr</code> methods. We also have a <code class="language-plaintext highlighter-rouge">__call__</code> method that invokes any forward method we define.</p> <p>With this Module class, we can extend it to create our own custom modules. For example, we can create a <code class="language-plaintext highlighter-rouge">OtherModule</code> class that inherits from <code class="language-plaintext highlighter-rouge">Module</code>.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">OtherModule</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="c1"># Must initialize the super class!
</span>        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">uncool_parameter</span> <span class="o">=</span> <span class="nc">Parameter</span><span class="p">(</span><span class="mi">60</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">MyModule</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="c1"># Must initialize the super class!
</span>        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>

        <span class="c1"># Parameters.
</span>        <span class="n">self</span><span class="p">.</span><span class="n">parameter1</span> <span class="o">=</span> <span class="nc">Parameter</span><span class="p">(</span><span class="mi">15</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">cool_parameter</span> <span class="o">=</span> <span class="nc">Parameter</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span>

        <span class="c1"># User data
</span>        <span class="n">self</span><span class="p">.</span><span class="n">data</span> <span class="o">=</span> <span class="mi">25</span>

        <span class="c1"># Submodules
</span>        <span class="n">self</span><span class="p">.</span><span class="n">sub_module_a</span> <span class="o">=</span> <span class="nc">OtherModule</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">sub_module_b</span> <span class="o">=</span> <span class="nc">OtherModule</span><span class="p">()</span>
</code></pre></div></div> <p>This is a simple toy example, but it illustrates how we might define useful modules like <code class="language-plaintext highlighter-rouge">Linear</code>, <code class="language-plaintext highlighter-rouge">Conv2d</code>, etc. In practice, this could look like a a ResNet module that contains convolutional and lienar submodules, with these submodules containing their own parameters (model weights).</p> <h2 id="part-2-autodiff">Part 2: Autodiff</h2> <p>The next part of the class is all about differentiation: how do we actually compute and store gradients for training?</p> <p>One approach we can take is symbolic differentiation, where we explicitly find the mathematical expression for the gradient of the function (as we would do in calculus class). This makes sense for simple functions like \(f(x) = x^2\), but becomes impractical for the more complex functions that would represent a neural network. Solving and storing such an expression explodes with model size.</p> <p>Another approach is numerical differentiation, where we approximate the gradient by altering inputs slightly and observing the change in output. The issue here is a) numerical instability due to approximation errors and b) we would need to compute the gradient for each parameter. We can imagine that for contemporary models with billions of parameters, this is impractical.</p> <p>To address these issues, automatic differentiation (autodiff) is the approach used in practice, which essentially collects information about every operation we perform in the forward pass, and uses this information to compute gradients in the backward pass. We can represent this collection and flow of information as a graph. With autodiff, we compute exact gradients like with symbolic differentiation, but we only need to evaluate each operation once (unlike numerical differentiation), since we store intermediate gradient accumulation values rather than entire expressions. Thus, autodiff is precise and scalable.</p> <pre><code class="language-mermaid">graph LR
    x1[x = 2.0] --&gt; mul1[×]
    x2[x = 2.0] --&gt; mul1
    mul1 --&gt; add1[+]
    x3[x = 2.0] --&gt; mul2[×]
    x4[x = 2.0] --&gt; mul2
    mul2 --&gt; add1
    add1 --&gt; result[y = 8.0]

    %% Add gradient flow
    result -- ∂y/∂+ = 1.0 --&gt; add1
    add1 -- ∂y/∂× = 1.0 --&gt; mul1
    add1 -- ∂y/∂× = 1.0 --&gt; mul2
    mul1 -- ∂y/∂x = 2.0 --&gt; x1
    mul1 -- ∂y/∂x = 2.0 --&gt; x2
    mul2 -- ∂y/∂x = 2.0 --&gt; x3
    mul2 -- ∂y/∂x = 2.0 --&gt; x4
</code></pre> <p>To do so in Python, we must override the default behavior of numbers and operators. To this end, we define proxy <code class="language-plaintext highlighter-rouge">Scalar</code> and <code class="language-plaintext highlighter-rouge">ScalarFunction</code> classes that allow us to remember what operators were used on what numbers.</p> <p>As an example, see how we define the multiplication operation:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Mul</span><span class="p">(</span><span class="n">ScalarFunction</span><span class="p">):</span>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">ctx</span><span class="p">.</span><span class="nf">save_for_backward</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="n">y</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">d</span><span class="p">):</span>
        <span class="c1"># Compute f'_x(x, y) * d, f'_y(x, y) * d
</span>        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">ctx</span><span class="p">.</span><span class="n">saved_values</span>
        <span class="n">f_x_prime</span> <span class="o">=</span> <span class="n">y</span>
        <span class="n">f_y_prime</span> <span class="o">=</span> <span class="n">x</span>
        <span class="k">return</span> <span class="n">f_x_prime</span> <span class="o">*</span> <span class="n">d</span><span class="p">,</span> <span class="n">f_y_prime</span> <span class="o">*</span> <span class="n">d</span>
</code></pre></div></div> <h2 id="part-3-tensors">Part 3: Tensors</h2> <p>Data structures for storing and manipulating data.</p> <h2 id="part-4-efficiency">Part 4: Efficiency</h2>]]></content><author><name></name></author><summary type="html"><![CDATA[My notes from completing Machine Learning Engineering at Cornell Tech]]></summary></entry><entry><title type="html">Limits to Prediction</title><link href="https://evan-wang-13.github.io/blog/2024/LimitsToPrediction/" rel="alternate" type="text/html" title="Limits to Prediction"/><published>2024-04-29T00:00:00+00:00</published><updated>2024-04-29T00:00:00+00:00</updated><id>https://evan-wang-13.github.io/blog/2024/LimitsToPrediction</id><content type="html" xml:base="https://evan-wang-13.github.io/blog/2024/LimitsToPrediction/"><![CDATA[<p>This spring, I took my favorite class at Princeton: the seminar <a href="https://msalganik.github.io/soc555-cos598J_s2024/">Limits to Prediction</a>, taught by Arvind Narayanan and Matt Salganik. Limits to Prediction featured a lecture-discussion format where both professors, along with students, discussed and responded to presented material. The widely applicable takeaways–ranging from why we make predictions to the pitfalls of AI benchmarking–were extremely impactful for me. Here are my notes that I want to keep in mind throughout my academic career and beyond.</p> <h2 id="meta-level-choosing-what-to-learnresearch">Meta-Level: Choosing What to Learn/Research</h2> <ul> <li>Choosing what to focus on in learning and research is a prediction task in and of itself. What will be super important in the next few years (or decades) that is not receiving enough attention already?</li> </ul> <p>A tangential discussion is the concept of strongly-held weak beliefs vs. weakly-held strong beliefs. Strongly-held weak beliefs are hypotheses that may not push the envelope super far from established knowledge, but we can be relatively confident in that belief. These beliefs are more foundational than ground-breaking. Weakly-held strong beliefs are beliefs that are “hot takes” but have low confidence. Some examples: Matt has a strongly-held weak belief that for a domain like music, randomness and luck can significantly determine how popular a song is-merit and quality is not a fool-proof determiner of success. Arvind has a weakly-held strong belief that the issues with LLM evaluation (contamination, prompt sensitivity, robustness, and more that we will get into in this post) are not fixable, and thus future work should be oriented towards replacing benchmarking rather than fixing it.</p> <p>Usual discourse pits these against each other-which should an aspiring researcher follow? This may be true at an individual level, but they certainly are not mutually exclusive at a larger scale. Both types of beliefs are important to have in the marketplace of ideas: diversity here is healthy.</p> <p>Matt describes himself as someone having strongly-held weak beliefs, while Arvind considers himself as having weakly-held strong beliefs.</p> <h2 id="evaluations-are-everything">Evaluations are Everything</h2> <ul> <li>Data Leakage and the <a href="https://projecteuclid.org/journals/statistical-science/volume-21/issue-1/Classifier-Technology-and-the-Illusion-of-Progress/10.1214/088342306000000060.full">ping-pong theorem</a>. You can read more about data leakage <a href="https://reproducible.cs.princeton.edu/">here</a>.</li> <li>Crucially, there is often a mismatch between training loss, performance evaluation, and what actually matters post-deployment. For example, say we are using some classifcation model. We might use maximum likelihood estimation to find the models’ parameters, some misclassification rate to evaluate the model, but in practice, what truly matters is a particular cost-weighted misclassification rate. It should be imperative to take time and ensure coherency here.</li> </ul> <p>For a particularly illuminating example, let’s look at the discussion over emergent abilities of LLMS.</p> <p>2022 paper evaluated LLM performance on some popular benchmarks as a function of parameter size. Contrary to traditional scaling laws, models achieve random performance up to a certain scale, then improves-sharply and unpredictably. This is a pretty crucial finding. If models truly exhibit emergent abilities, that makes predicting their predictive power, abilities, and risks much harder. A bunch of steps and research would probably need to follow.</p> <p>But! A 2023 <a href="https://arxiv.org/abs/2304.15004">paper</a> suggests this is not the full picture. “emergent abilities seem to appear only under metrics that nonlinearly or discontinuously scale any model’s per-token error rate.”</p> <p>Results of testing this hypothesis are shown below, taken from their paper. For completeness, the first column follows a simple mathematical model, where they assume cross entropy loss decreases monotonically with scale, and thus per-token probability of selecting the right token asymptotes towards 1.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/emergentMirage-480.webp 480w,/assets/img/emergentMirage-800.webp 800w,/assets/img/emergentMirage-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/emergentMirage.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>When we go from a non-linear metric, where the scoring tends to be more binary with a strict threshold, to a non-linear metric, the emergent pattern seems to disappear. So what is the “correct” metric to use? It probably doesn’t matter that much-ultimately whatever allows us to make the best predictions for the desired task. But, overall, this recasts emergence from a model property to something about how we evaluate/consider knowledge.</p> ]]></content><author><name></name></author><summary type="html"><![CDATA[What I learned from my favorite class at Princeton. Will continue to update as I parse through my notes.]]></summary></entry></feed>