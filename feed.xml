<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://evan-wang-13.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://evan-wang-13.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-05-23T04:52:57+00:00</updated><id>https://evan-wang-13.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Limits to Prediction-Biggest Takeaways</title><link href="https://evan-wang-13.github.io/blog/2024/LimitsToPrediction/" rel="alternate" type="text/html" title="Limits to Prediction-Biggest Takeaways"/><published>2024-04-29T00:00:00+00:00</published><updated>2024-04-29T00:00:00+00:00</updated><id>https://evan-wang-13.github.io/blog/2024/LimitsToPrediction</id><content type="html" xml:base="https://evan-wang-13.github.io/blog/2024/LimitsToPrediction/"><![CDATA[<p>This spring, I took my favorite class at Princeton: the seminar <a href="https://msalganik.github.io/soc555-cos598J_s2024/">Limits to Prediction</a>, taught by Arvind Narayanan and Matt Salganik. lecture-discussion format where both professors, along with students, would be able to respond to the presented material. The topics, open discussions, and view-altering takeaway made this an eye-opening experience.</p> <h2 id="meta-level-choosing-what-to-learnresearch">Meta-Level: Choosing What to Learn/Research</h2> <ul> <li>This involves a prediction task: what will be super important that is not receiving enough attention already?</li> </ul> <h2 id="evaluations-are-everything">Evaluations are Everything</h2> <ul> <li>Data Leakage and the ping-pong hacking theorem</li> <li>Mismatch between training loss, performance evaluation, and what actually matters post-deployment. For example, for a classification model, we might use maximum likelihood estimation to find the modelsâ€™ parameters, some misclassification rate to evaluate the model, but in practice, what matters is some cost-weighted misclassification.</li> <li>LLM- emergent abilities or a product of eval metric?</li> </ul> ]]></content><author><name></name></author><summary type="html"><![CDATA[What I learned from my favorite class at Princeton. Will continue to update as I parse through my notes.]]></summary></entry></feed>