<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://evan-wang-13.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://evan-wang-13.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-12-22T19:29:16+00:00</updated><id>https://evan-wang-13.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Building MiniTorch</title><link href="https://evan-wang-13.github.io/blog/2024/MLE/" rel="alternate" type="text/html" title="Building MiniTorch"/><published>2024-12-21T00:00:00+00:00</published><updated>2024-12-21T00:00:00+00:00</updated><id>https://evan-wang-13.github.io/blog/2024/MLE</id><content type="html" xml:base="https://evan-wang-13.github.io/blog/2024/MLE/"><![CDATA[<p>In Machine Learning Engineering (MLE), taught by Prof. Sasha Rush, I built <a href="https://minitorch.github.io/">MiniTorch</a>, a ground-up implementation of PyTorch. Starting from basis scalar operations, I implemented a fully operational Python library for training neural networks.</p> <p>I think this was a super unique class; getting to focus on the <em>engineering</em> side of Machine Learning Engineering was super cool. Now, when I call <code class="language-plaintext highlighter-rouge">torch.nn.Linear</code> or <code class="language-plaintext highlighter-rouge">loss.backward()</code>, I know what’s happening under the hood. These are my key takeaways!</p> <h2 id="part-1-fundamentals">Part 1: Fundamentals</h2> <p>Our goal is to implement code that allows us to train large neural networks. This requires keeping track of many parameters, as well as tracing operations to compute gradients. We do this by using a <code class="language-plaintext highlighter-rouge">Module</code> building block that is maintained in a tree structure. Each module stores its own parameters, as well as its submodules.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">relu</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="sh">"""</span><span class="s">Compute the ReLU (Rectified Linear Unit) function.</span><span class="sh">"""</span>
    <span class="k">return</span> <span class="nf">max</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">map</span><span class="p">(</span><span class="n">fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">float</span><span class="p">],</span> <span class="nb">float</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Iterable</span><span class="p">[</span><span class="nb">float</span><span class="p">]],</span> <span class="n">Iterable</span><span class="p">[</span><span class="nb">float</span><span class="p">]]:</span>
    <span class="sh">"""</span><span class="s">Apply a function to each element of an iterable.

    Args:
    ----
        fn: A function that takes a float and returns a float.

    Returns:
    -------
        A function that takes an iterable of floats and returns an iterable of floats
        with the input function applied to each element.

    </span><span class="sh">"""</span>

    <span class="k">def</span> <span class="nf">inner</span><span class="p">(</span><span class="n">ls</span><span class="p">:</span> <span class="n">Iterable</span><span class="p">[</span><span class="nb">float</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Iterable</span><span class="p">[</span><span class="nb">float</span><span class="p">]:</span>
        <span class="k">return</span> <span class="p">[</span><span class="nf">fn</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">ls</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">inner</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">OtherModule</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="c1"># Must initialize the super class!
</span>        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">uncool_parameter</span> <span class="o">=</span> <span class="nc">Parameter</span><span class="p">(</span><span class="mi">60</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">MyModule</span><span class="p">(</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="c1"># Must initialize the super class!
</span>        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>

        <span class="c1"># Type 1, a parameter.
</span>        <span class="n">self</span><span class="p">.</span><span class="n">parameter1</span> <span class="o">=</span> <span class="nc">Parameter</span><span class="p">(</span><span class="mi">15</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">cool_parameter</span> <span class="o">=</span> <span class="nc">Parameter</span><span class="p">(</span><span class="mi">50</span><span class="p">)</span>

        <span class="c1"># Type 2, user data
</span>        <span class="n">self</span><span class="p">.</span><span class="n">data</span> <span class="o">=</span> <span class="mi">25</span>

        <span class="c1"># Type 3. another Module
</span>        <span class="n">self</span><span class="p">.</span><span class="n">sub_module_a</span> <span class="o">=</span> <span class="nc">OtherModule</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">sub_module_b</span> <span class="o">=</span> <span class="nc">OtherModule</span><span class="p">()</span>
</code></pre></div></div> <h2 id="part-2-autodiff">Part 2: Autodiff</h2> <h2 id="part-3-tensors">Part 3: Tensors</h2> <h2 id="part-4-efficiency">Part 4: Efficiency</h2>]]></content><author><name></name></author><summary type="html"><![CDATA[My notes from completing Machine Learning Engineering at Cornell Tech]]></summary></entry><entry><title type="html">Limits to Prediction-Biggest Takeaways</title><link href="https://evan-wang-13.github.io/blog/2024/LimitsToPrediction/" rel="alternate" type="text/html" title="Limits to Prediction-Biggest Takeaways"/><published>2024-04-29T00:00:00+00:00</published><updated>2024-04-29T00:00:00+00:00</updated><id>https://evan-wang-13.github.io/blog/2024/LimitsToPrediction</id><content type="html" xml:base="https://evan-wang-13.github.io/blog/2024/LimitsToPrediction/"><![CDATA[<p>This spring, I took my favorite class at Princeton: the seminar <a href="https://msalganik.github.io/soc555-cos598J_s2024/">Limits to Prediction</a>, taught by Arvind Narayanan and Matt Salganik. Limits to Prediction featured a lecture-discussion format where both professors, along with students, discussed and responded to presented material. The widely applicable takeaways–ranging from why we make predictions to the pitfalls of AI benchmarking–were extremely impactful for me. Here are my notes that I want to keep in mind throughout my academic career and beyond.</p> <h2 id="meta-level-choosing-what-to-learnresearch">Meta-Level: Choosing What to Learn/Research</h2> <ul> <li>Choosing what to focus on in learning and research is a prediction task in and of itself. What will be super important in the next few years (or decades) that is not receiving enough attention already?</li> </ul> <p>A tangential discussion is the concept of strongly-held weak beliefs vs. weakly-held strong beliefs. Strongly-held weak beliefs are hypotheses that may not push the envelope super far from established knowledge, but we can be relatively confident in that belief. These beliefs are more foundational than ground-breaking. Weakly-held strong beliefs are beliefs that are “hot takes” but have low confidence. Some examples: Matt has a strongly-held weak belief that for a domain like music, randomness and luck can significantly determine how popular a song is-merit and quality is not a fool-proof determiner of success. Arvind has a weakly-held strong belief that the issues with LLM evaluation (contamination, prompt sensitivity, robustness, and more that we will get into in this post) are not fixable, and thus future work should be oriented towards replacing benchmarking rather than fixing it.</p> <p>Usual discourse pits these against each other-which should an aspiring researcher follow? This may be true at an individual level, but they certainly are not mutually exclusive at a larger scale. Both types of beliefs are important to have in the marketplace of ideas: diversity here is healthy.</p> <p>Matt describes himself as someone having strongly-held weak beliefs, while Arvind considers himself as having weakly-held strong beliefs.</p> <h2 id="evaluations-are-everything">Evaluations are Everything</h2> <ul> <li>Data Leakage and the <a href="https://projecteuclid.org/journals/statistical-science/volume-21/issue-1/Classifier-Technology-and-the-Illusion-of-Progress/10.1214/088342306000000060.full">ping-pong theorem</a>. You can read more about data leakage <a href="https://reproducible.cs.princeton.edu/">here</a>.</li> <li>Crucially, there is often a mismatch between training loss, performance evaluation, and what actually matters post-deployment. For example, say we are using some classifcation model. We might use maximum likelihood estimation to find the models’ parameters, some misclassification rate to evaluate the model, but in practice, what truly matters is a particular cost-weighted misclassification rate. It should be imperative to take time and ensure coherency here.</li> </ul> <p>For a particularly illuminating example, let’s look at the discussion over emergent abilities of LLMS.</p> <p>2022 paper evaluated LLM performance on some popular benchmarks as a function of parameter size. Contrary to traditional scaling laws, models achieve random performance up to a certain scale, then improves-sharply and unpredictably. This is a pretty crucial finding. If models truly exhibit emergent abilities, that makes predicting their predictive power, abilities, and risks much harder. A bunch of steps and research would probably need to follow.</p> <p>But! A 2023 <a href="https://arxiv.org/abs/2304.15004">paper</a> suggests this is not the full picture. “emergent abilities seem to appear only under metrics that nonlinearly or discontinuously scale any model’s per-token error rate.”</p> <p>Results of testing this hypothesis are shown below, taken from their paper. For completeness, the first column follows a simple mathematical model, where they assume cross entropy loss decreases monotonically with scale, and thus per-token probability of selecting the right token asymptotes towards 1.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/emergentMirage-480.webp 480w,/assets/img/emergentMirage-800.webp 800w,/assets/img/emergentMirage-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/emergentMirage.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>When we go from a non-linear metric, where the scoring tends to be more binary with a strict threshold, to a non-linear metric, the emergent pattern seems to disappear. So what is the “correct” metric to use? It probably doesn’t matter that much-ultimately whatever allows us to make the best predictions for the desired task. But, overall, this recasts emergence from a model property to something about how we evaluate/consider knowledge.</p> ]]></content><author><name></name></author><summary type="html"><![CDATA[What I learned from my favorite class at Princeton. Will continue to update as I parse through my notes.]]></summary></entry></feed>