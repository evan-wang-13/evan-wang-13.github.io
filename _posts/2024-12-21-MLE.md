---
layout: post
title: Building MiniTorch
description: My notes from completing Machine Learning Engineering at Cornell Tech
date: 2024-12-21
featured: true
toc:
  beginning: true
---

In Machine Learning Engineering (MLE), taught by Prof. Sasha Rush, I built [MiniTorch](https://minitorch.github.io/), a ground-up implementation of PyTorch. Starting from basis scalar operations, I implemented a fully operational Python library for training neural networks.

I think this was a super unique class; getting to focus on the _engineering_ side of Machine Learning Engineering was super cool. Now, when I call `torch.nn.Linear` or `loss.backward()`, I know what's happening under the hood. These are my key takeaways!

## Part 1: Fundamentals

Our goal is to implement code that allows us to train large neural networks. This requires keeping track of many parameters, as well as tracing operations to compute gradients. We do this by using a `Module` building block that is maintained in a tree structure. Each module stores its own parameters, as well as its submodules.

```python
def relu(x: float) -> float:
    """Compute the ReLU (Rectified Linear Unit) function."""
    return max(0.0, x)
```

```python
def map(fn: Callable[[float], float]) -> Callable[[Iterable[float]], Iterable[float]]:
    """Apply a function to each element of an iterable.

    Args:
    ----
        fn: A function that takes a float and returns a float.

    Returns:
    -------
        A function that takes an iterable of floats and returns an iterable of floats
        with the input function applied to each element.

    """

    def inner(ls: Iterable[float]) -> Iterable[float]:
        return [fn(x) for x in ls]

    return inner
```

```python
class OtherModule(Module):
    def __init__(self):
        # Must initialize the super class!
        super().__init__()
        self.uncool_parameter = Parameter(60)


class MyModule(Module):
    def __init__(self):
        # Must initialize the super class!
        super().__init__()

        # Type 1, a parameter.
        self.parameter1 = Parameter(15)
        self.cool_parameter = Parameter(50)

        # Type 2, user data
        self.data = 25

        # Type 3. another Module
        self.sub_module_a = OtherModule()
        self.sub_module_b = OtherModule()
```

## Part 2: Autodiff

## Part 3: Tensors

## Part 4: Efficiency
