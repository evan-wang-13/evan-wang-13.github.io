---
layout: post
title: Building MiniTorch
description: My notes from completing Machine Learning Engineering at Cornell Tech
date: 2024-12-21
featured: true
---

In Machine Learning Engineering (MLE), taught by Prof. Sasha Rush, I built [MiniTorch](https://minitorch.github.io/), a ground-up implementation of PyTorch. Starting from basis scalar operations, I implemented a fully operational Python library for training neural networks.

I think this was a super unique class; getting to focus on the _engineering_ side of Machine Learning Engineering was super cool. Now, when I call `torch.nn.Linear` or `loss.backward()`, I know what's happening under the hood. These are my key takeaways!

```c++
int main(int argc, char const \*argv[])
{
    string myString;

    cout << "input a string: ";
    getline(cin, myString);
    int length = myString.length();

    char charArray = new char * [length];

    charArray = myString;
    for(int i = 0; i < length; ++i){
        cout << charArray[i] << " ";
    }

    return 0;
}
```

```python
class Neg(ScalarFunction):
@staticmethod
def forward(ctx, x):
return -x

    @staticmethod
    def backward(ctx, d):
        f_prime = -1
        return f_prime * d
```
